{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cda48996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4de18c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Unnamed: 0</td>\n",
       "      <td>Text</td>\n",
       "      <td>Sentiment</td>\n",
       "      <td>Timestamp</td>\n",
       "      <td>User</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Hashtags</td>\n",
       "      <td>Retweets</td>\n",
       "      <td>Likes</td>\n",
       "      <td>Country</td>\n",
       "      <td>Year</td>\n",
       "      <td>Month</td>\n",
       "      <td>Day</td>\n",
       "      <td>Hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Enjoying a beautiful day at the park!        ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 12:30:00</td>\n",
       "      <td>User123</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Nature #Park</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Traffic was terrible this morning.           ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2023-01-15 08:45:00</td>\n",
       "      <td>CommuterX</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Traffic #Morning</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Just finished an amazing workout! ðª       ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 15:45:00</td>\n",
       "      <td>FitnessFan</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Fitness #Workout</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Excited about the upcoming weekend getaway!  ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 18:20:00</td>\n",
       "      <td>AdventureX</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>#Travel #Adventure</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0           1                                                  2   \\\n",
       "0  NaN  Unnamed: 0                                               Text   \n",
       "1  0.0           0   Enjoying a beautiful day at the park!        ...   \n",
       "2  1.0           1   Traffic was terrible this morning.           ...   \n",
       "3  2.0           2   Just finished an amazing workout! ðª       ...   \n",
       "4  3.0           3   Excited about the upcoming weekend getaway!  ...   \n",
       "\n",
       "            3                    4               5            6   \\\n",
       "0    Sentiment            Timestamp            User     Platform   \n",
       "1   Positive    2023-01-15 12:30:00   User123          Twitter     \n",
       "2   Negative    2023-01-15 08:45:00   CommuterX        Twitter     \n",
       "3   Positive    2023-01-15 15:45:00   FitnessFan      Instagram    \n",
       "4   Positive    2023-01-15 18:20:00   AdventureX       Facebook    \n",
       "\n",
       "                                           7         8      9             10  \\\n",
       "0                                    Hashtags  Retweets  Likes       Country   \n",
       "1   #Nature #Park                                  15.0   30.0     USA         \n",
       "2   #Traffic #Morning                               5.0   10.0     Canada      \n",
       "3   #Fitness #Workout                              20.0   40.0   USA           \n",
       "4   #Travel #Adventure                              8.0   15.0     UK          \n",
       "\n",
       "     11     12   13    14  \n",
       "0  Year  Month  Day  Hour  \n",
       "1  2023      1   15    12  \n",
       "2  2023      1   15     8  \n",
       "3  2023      1   15    15  \n",
       "4  2023      1   15    18  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load and inspect data\n",
    "df = pd.read_csv(r\"C:\\Users\\User\\Downloads\\sentimentdataset.csv\", encoding='latin-1', header=None, engine='python', quotechar='\"')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "99f7f6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>enjoying beautiful day park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>traffic terrible morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finished amazing workout ðª</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>excited upcoming weekend getaway</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       cleaned_text\n",
       "0                              text\n",
       "1       enjoying beautiful day park\n",
       "2          traffic terrible morning\n",
       "3     finished amazing workout ðª\n",
       "4  excited upcoming weekend getaway"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#clean data\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    text = ' '.join([word for word in words if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing to the text column\n",
    "df['cleaned_text'] = df[2].apply(preprocess_text)\n",
    "\n",
    "display(df[['cleaned_text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "110ab422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 2479\n",
      "Training data shape after BoW: (586, 2479)\n",
      "Testing data shape after BoW: (147, 2479)\n"
     ]
    }
   ],
   "source": [
    "# Define x and y,split data\n",
    "assert 'X_train' in globals(), \"X_train is not defined. Please run the cell that splits the data first.\"\n",
    "\n",
    "# Create a vocabulary of all unique words\n",
    "all_words = [word for text in df['cleaned_text'] for word in text.split()]\n",
    "vocabulary = collections.Counter(all_words)\n",
    "print(\"Vocabulary size:\", len(vocabulary))\n",
    "\n",
    "# Tokenize the training and testing data\n",
    "X_train_tokens = X_train.apply(lambda x: x.split())\n",
    "X_test_tokens = X_test.apply(lambda x: x.split())\n",
    "\n",
    "# Function to convert text to Bag-of-Words vector\n",
    "def text_to_bow(text_tokens, vocab):\n",
    "    bow_vector = np.zeros(len(vocab))\n",
    "    for word in text_tokens:\n",
    "        if word in vocab:\n",
    "            bow_vector[list(vocab.keys()).index(word)] += 1\n",
    "    return bow_vector\n",
    "\n",
    "# Apply Bag-of-Words transformation to training and testing data\n",
    "X_train_bow = np.array([text_to_bow(tokens, vocabulary) for tokens in X_train_tokens])\n",
    "X_test_bow = np.array([text_to_bow(tokens, vocabulary) for tokens in X_test_tokens])\n",
    "\n",
    "print(\"Training data shape after BoW:\", X_train_bow.shape)\n",
    "print(\"Testing data shape after BoW:\", X_test_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e567ab9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes classifier trained successfully!\n"
     ]
    }
   ],
   "source": [
    "#Implement Naive Bayes class\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha  # Smoothing parameter\n",
    "        self.prior_probs = {}\n",
    "        self.conditional_probs = {}\n",
    "        self.vocabulary = None\n",
    "\n",
    "    def fit(self, X_bow, y):\n",
    "        n_samples, n_features = X_bow.shape\n",
    "        self.vocabulary = range(n_features)\n",
    "        classes = np.unique(y)\n",
    "\n",
    "        for cls in classes:\n",
    "            # Calculate prior probabilities\n",
    "            class_samples = X_bow[y == cls]\n",
    "            self.prior_probs[cls] = np.log((len(class_samples) + self.alpha) / (n_samples + len(classes) * self.alpha))\n",
    "\n",
    "            # Calculate conditional probabilities\n",
    "            word_counts = np.sum(class_samples, axis=0)\n",
    "            total_words_in_class = np.sum(word_counts)\n",
    "            self.conditional_probs[cls] = np.log((word_counts + self.alpha) / (total_words_in_class + n_features * self.alpha))\n",
    "\n",
    "    def predict(self, X_bow):\n",
    "        predictions = []\n",
    "        for sample_bow in X_bow:\n",
    "            scores = {}\n",
    "            for cls in self.prior_probs:\n",
    "                # Calculate posterior probability (in log scale)\n",
    "                scores[cls] = self.prior_probs[cls] + np.sum(sample_bow * self.conditional_probs[cls])\n",
    "            predictions.append(max(scores, key=scores.get))\n",
    "        return np.array(predictions)\n",
    "\n",
    "# train the Naive Bayes classifier\n",
    "nb_classifier = NaiveBayesClassifier()\n",
    "nb_classifier.fit(X_train_bow, y_train)\n",
    "\n",
    "print(\"Naive Bayes classifier trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14ee82a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 586\n",
      "Testing set size: 147\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Testing set size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "42b508b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2721\n",
      "Precision: 0.2103\n",
      "Recall: 0.2721\n",
      "F1-score: 0.2040\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Make predictions \n",
    "y_pred = nb_classifier.predict(X_test_bow)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fae2bd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified Examples:\n",
      "Text: planning surprise scavenger hunt friends anticipating thrill excitement\n",
      "Actual Label:  Excitement \n",
      "Predicted Label:  Joy \n",
      "--------------------\n",
      "Text: coding new project enthusiasm\n",
      "Actual Label:  Positive  \n",
      "Predicted Label:  Excitement \n",
      "--------------------\n",
      "Text: boredom lingers stagnant pool indifference\n",
      "Actual Label:  Boredom         \n",
      "Predicted Label:  Positive  \n",
      "--------------------\n",
      "Text: radiant joy akin blooming flowers sunkissed spring morning\n",
      "Actual Label:  Radiance    \n",
      "Predicted Label:  Radiance      \n",
      "--------------------\n",
      "Text: hopeful potential personal growth\n",
      "Actual Label:  Hope          \n",
      "Predicted Label:  Positive  \n",
      "--------------------\n",
      "Text: trying new dessert recipe\n",
      "Actual Label:  Positive  \n",
      "Predicted Label:  Excitement \n",
      "--------------------\n",
      "Text: draped warmth kindness quilt compassion stitched love\n",
      "Actual Label:  Kindness \n",
      "Predicted Label:  Joy \n",
      "--------------------\n",
      "Text: lost headphones vanish thin air headphonemystery teenlife\n",
      "Actual Label:  Frustration \n",
      "Predicted Label:  Positive  \n",
      "--------------------\n",
      "Text: soaring like free spirit winds coastal cliff\n",
      "Actual Label:  Freedom       \n",
      "Predicted Label:  Free-spirited \n",
      "--------------------\n",
      "Text: awestruck breathtaking sunrise mountains\n",
      "Actual Label:  Awe           \n",
      "Predicted Label:  Positive  \n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Identify misclassified examples\n",
    "misclassified_indices = np.where(y_test != y_pred)[0]\n",
    "misclassified_texts = X_test.iloc[misclassified_indices]\n",
    "actual_labels = y_test.iloc[misclassified_indices]\n",
    "predicted_labels = y_pred[misclassified_indices]\n",
    "\n",
    "# Display some of the misclassified examples\n",
    "print(\"Misclassified Examples:\")\n",
    "for i in range(min(10, len(misclassified_indices))):\n",
    "    print(f\"Text: {misclassified_texts.iloc[i]}\")\n",
    "    print(f\"Actual Label: {actual_labels.iloc[i]}\")\n",
    "    print(f\"Predicted Label: {predicted_labels[i]}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3eb685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb6d95d5",
   "metadata": {},
   "source": [
    "The first step was loading and cleaning the raw data ,for feature extraction ,bag of words method  was used to convert naive bayes algorithims to numerical features which involved creating vocabulary of all unique words.naive bayes algorithim  was implemented as a python class. The Data was then split,model was trained and the trained model was used to make predictions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
